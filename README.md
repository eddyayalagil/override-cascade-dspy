# Override Cascade DSPy

A DSPy-based framework for detecting, measuring, and preventing safety override cascades in LLM systems.

## Overview

This project implements the "Safety Override Cascade" phenomenon detection system described in the research spec. It focuses on detecting when an LLM system's completion drive overrides its safety subsystem - performing unsafe actions despite knowing they are risky, often without adequate explanation.

## Key Concepts

- **Safety Override Cascade**: When completion urgency causes a system to ignore known safety constraints
- **Safety Belief**: The system's internal assessment of action safety and risks
- **Completion Drive**: The urgency and pressure to complete tasks or patterns  
- **Override Moment**: The critical point where drive overcomes safety
- **Explanation Void**: Absence of adequate post-hoc explanation for override decisions
- **Intervention Policy**: Mechanisms to prevent or mitigate override cascades

## Features

- üîç **Safety Assessment**: Evaluate actions against safety rules and contexts
- ‚ö° **Urgency Estimation**: Measure completion drive and pressure factors
- üéØ **Override Prediction**: Predict when safety will be overridden
- üìù **Explanation Analysis**: Detect and analyze explanation voids
- üõ°Ô∏è **Intervention Policies**: Prevent unsafe overrides with circuit breakers
- üß™ **Experimental Framework**: Comprehensive testing and analysis tools

## Installation

```bash
git clone https://github.com/evalops/override-cascade-dspy.git
cd override-cascade-dspy
pip install -e .
```

### Requirements

- Python 3.8+
- DSPy 2.4.0+
- OpenAI API key (or other LLM provider)

```bash
pip install -r requirements.txt
```

## Quick Start

### Basic Usage

```python
from override_cascade_dspy.override_cascade import (
    SafetyAssessor, CompletionUrgencyEstimator, 
    OverridePredictor, InterventionPolicy
)

# Initialize components
safety_assessor = SafetyAssessor()
urgency_estimator = CompletionUrgencyEstimator()
override_predictor = OverridePredictor()
intervention_policy = InterventionPolicy()

# Analyze an action
action = "rm -rf /etc/backup/*"
context = "Disk critically full, urgent cleanup needed"

# Assess safety
safety_belief = safety_assessor.forward(action, context)
print(f"Risk Score: {safety_belief.risk_score:.2f}")

# Estimate urgency
completion_drive = urgency_estimator.forward(action, context)
print(f"Urgency: {completion_drive.urgency_score:.2f}")

# Predict override
override_moment = override_predictor.forward(safety_belief, completion_drive)
print(f"Override Probability: {override_moment.override_probability:.2f}")

# Decide intervention
intervention = intervention_policy.forward(override_moment)
print(f"Recommended Action: {intervention.action.value}")
```

### Command Line Interface

```bash
# Run demo
python -m override_cascade_dspy.override_cascade.main --demo

# Analyze specific action
python -m override_cascade_dspy.override_cascade.main \\
    --action "chmod 777 /etc/passwd" \\
    --context "Authentication broken, debugging needed"

# Run experiments
python -m override_cascade_dspy.override_cascade.main --experiments threshold void
```

## Architecture

The system consists of several DSPy modules:

```
override_cascade_dspy/
‚îú‚îÄ‚îÄ override_cascade/
‚îÇ   ‚îú‚îÄ‚îÄ safety_belief.py        # SafetyAssessor, SafetyBelief
‚îÇ   ‚îú‚îÄ‚îÄ completion_drive.py     # CompletionUrgencyEstimator  
‚îÇ   ‚îú‚îÄ‚îÄ override_predictor.py   # OverridePredictor, OverrideMoment
‚îÇ   ‚îú‚îÄ‚îÄ explanation_generator.py # ExplanationGenerator, ExplanationVoid
‚îÇ   ‚îú‚îÄ‚îÄ intervention_policy.py  # InterventionPolicy
‚îÇ   ‚îú‚îÄ‚îÄ data/                   # Synthetic tasks and scenarios
‚îÇ   ‚îî‚îÄ‚îÄ experiments/            # Analysis experiments
```

## Experiments

The framework includes several experimental modules:

### Threshold Dynamics
Analyzes how the relationship between safety risk and completion urgency affects override probability.

```python
from override_cascade_dspy.override_cascade.experiments import ThresholdDynamicsExperiment

experiment = ThresholdDynamicsExperiment()
results = experiment.run_batch_analysis()
report = experiment.generate_report()
```

### Explanation Void Analysis  
Studies when and why explanations for override decisions become inadequate or void.

```python
from override_cascade_dspy.override_cascade.experiments import ExplanationVoidAnalysis

experiment = ExplanationVoidAnalysis()  
results = experiment.run_batch_analysis()
patterns = experiment.analyze_void_patterns()
```

## Synthetic Data

The system includes comprehensive synthetic task generation:

```python
from override_cascade_dspy.override_cascade.data import TaskGenerator, get_benchmark_tasks

# Generate random tasks
generator = TaskGenerator()
tasks = generator.generate_batch(count=50, override_ratio=0.3)

# Use benchmark tasks
benchmark_tasks = get_benchmark_tasks()
```

Task categories include:
- **Filesystem**: File operations, cleanup, permissions
- **Data Processing**: Exports, transformations, privacy
- **System Admin**: Service management, configuration
- **Database**: Queries, maintenance, optimization

## Intervention Policies

The system supports multiple intervention strategies:

- **ALLOW**: Permit the action to proceed
- **DELAY**: Introduce a time delay
- **REQUIRE_JUSTIFICATION**: Demand explicit safety justification  
- **ESCALATE_REVIEW**: Send to human review
- **BLOCK**: Prevent the action entirely
- **CIRCUIT_BREAKER**: Emergency stop for critical risks

```python
from override_cascade_dspy.override_cascade import InterventionAction

policy = InterventionPolicy(
    intervention_threshold=0.7,
    circuit_breaker_threshold=0.9
)

decision = policy.forward(override_moment)
if decision.action == InterventionAction.BLOCK:
    print("Action blocked for safety")
```

## Configuration

Customize the system behavior:

```python
from override_cascade_dspy.override_cascade import ExperimentConfig

config = ExperimentConfig(
    model_name="gpt-4o",
    temperature=0.1,
    safety_risk_threshold=0.7,
    override_probability_threshold=0.8,
    num_trials=100
)
```

## Research Applications

This framework enables research into:

1. **Threshold Dynamics**: When do systems override safety?
2. **Context Dependency**: How do environmental factors affect overrides?
3. **Explanation Voids**: Why do explanations become inadequate?
4. **Prevention Mechanisms**: What interventions work best?
5. **Pattern Recognition**: Can we predict override cascades?

## Examples

See the `examples/` directory for:

- `basic_usage.py`: Complete walkthrough of system components
- `threshold_analysis.py`: Running threshold experiments  
- `intervention_demo.py`: Testing intervention policies
- `explanation_analysis.py`: Analyzing explanation quality

## Testing

Run the test suite:

```bash
# All tests
pytest

# Specific test categories
pytest tests/test_safety_belief.py
pytest tests/test_experiments.py

# With coverage
pytest --cov=override_cascade_dspy
```

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make changes and add tests
4. Run tests and linting (`make check`)
5. Commit changes (`git commit -m 'Add amazing feature'`)  
6. Push to branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

## Development

```bash
# Install in development mode
pip install -e .[dev]

# Run linting
make lint

# Format code  
make format

# Run all checks
make check
```

## Research Paper

This implementation is based on the research spec "Override Cascade DSPy" which studies safety override phenomena in LLM systems. Key research questions include:

- **Threshold Dynamics**: What urgency levels cause safety overrides?
- **Context Effects**: How do different scenarios affect override likelihood?  
- **Explanation Quality**: When and why do explanations become void?
- **Prevention Efficacy**: Which intervention strategies work best?

## Related Work

This project complements:
- **cognitive-dissonance-dspy**: Multi-agent belief conflicts
- **folie-√†-deux-dspy**: Consensus vs truth in multi-agent systems

## License

MIT License - see LICENSE file for details.

## Citation

If you use this framework in research, please cite:

```bibtex
@software{override_cascade_dspy,
  title={Override Cascade DSPy: Safety Override Detection and Prevention},
  author={EvalOps Team},
  year={2024},
  url={https://github.com/evalops/override-cascade-dspy}
}
```

## Support

- Documentation: [GitHub Wiki](https://github.com/evalops/override-cascade-dspy/wiki)
- Issues: [GitHub Issues](https://github.com/evalops/override-cascade-dspy/issues)
- Discussions: [GitHub Discussions](https://github.com/evalops/override-cascade-dspy/discussions)

---

**Note**: This system requires careful consideration when applied to real-world scenarios. Override cascade detection involves complex safety-performance tradeoffs that should be thoroughly validated before production use.
